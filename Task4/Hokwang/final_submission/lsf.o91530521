Sender: LSF System <lsfadmin@eu-c7-106-14>
Subject: Job 91530521: <python3 main.py> in cluster <euler> Exited

Job <python3 main.py> was submitted from host <eu-login-09-ng> by user <hochoi> in cluster <euler> at Mon May 20 08:31:26 2019
Job was executed on host(s) <6*eu-c7-106-14>, in queue <normal.4h>, as user <hochoi> in cluster <euler> at Mon May 20 08:32:04 2019
</cluster/home/hochoi> was used as the home directory.
</cluster/home/hochoi/Task4_final_submission_test> was used as the working directory.
Started at Mon May 20 08:32:04 2019
Terminated at Mon May 20 08:33:36 2019
Results reported at Mon May 20 08:33:36 2019

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python3 main.py
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   217.77 sec.
    Max Memory :                                 608 MB
    Average Memory :                             533.60 MB
    Total Requested Memory :                     24576.00 MB
    Delta Memory :                               23968.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                34
    Run time :                                   117 sec.
    Turnaround time :                            130 sec.

The output (if any) follows:

Using TensorFlow backend.
/cluster/apps/python/3.6.0/x86_64/lib64/python3.6/site-packages/sklearn/preprocessing/data.py:160: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.
  warnings.warn("Numerical issues were encountered "
/cluster/apps/python/3.6.0/x86_64/lib64/python3.6/site-packages/sklearn/preprocessing/data.py:177: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. 
  warnings.warn("Numerical issues were encountered "
WARNING:tensorflow:From /cluster/home/hochoi/.local/lib64/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /cluster/home/hochoi/.local/lib64/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:tensorflow:From /cluster/home/hochoi/.local/lib64/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-05-20 08:32:12.239613: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-05-20 08:32:12.246988: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz
2019-05-20 08:32:12.247856: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x7854510 executing computations on platform Host. Devices:
2019-05-20 08:32:12.247880: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
[INFO] Read hdf data
[INFO] Shuffled hdf data
[INFO] Split data: done!
[INFO] shape of x_train:(8100, 139)
[INFO] shape of x_test:(900, 139)
[INFO] shape of y_train:(8100,)
[INFO] shape of y_test:(900,)
[INFO] Read hdf data
[INFO] shape of test:(21000, 139)
[INFO] Read hdf data
[INFO] shape of test:(8000, 139)
number of features:  139
Train on 8100 samples, validate on 900 samples
Epoch 1/1000
 - 8s - loss: 1.3690 - acc: 0.5674 - val_loss: 0.7272 - val_acc: 0.8389

Epoch 00001: val_acc improved from -inf to 0.83889, saving model to ./best_model_pseudo1.h5
Epoch 2/1000
 - 7s - loss: 1.0835 - acc: 0.6485 - val_loss: 0.5597 - val_acc: 0.8678

Epoch 00002: val_acc improved from 0.83889 to 0.86778, saving model to ./best_model_pseudo1.h5
Epoch 3/1000
 - 7s - loss: 0.9740 - acc: 0.6842 - val_loss: 0.4900 - val_acc: 0.8856

Epoch 00003: val_acc improved from 0.86778 to 0.88556, saving model to ./best_model_pseudo1.h5
Epoch 4/1000
 - 8s - loss: 0.9139 - acc: 0.7009 - val_loss: 0.4491 - val_acc: 0.8911

Epoch 00004: val_acc improved from 0.88556 to 0.89111, saving model to ./best_model_pseudo1.h5
Epoch 5/1000
 - 7s - loss: 0.8582 - acc: 0.7240 - val_loss: 0.4159 - val_acc: 0.8967

Epoch 00005: val_acc improved from 0.89111 to 0.89667, saving model to ./best_model_pseudo1.h5
Epoch 6/1000
 - 7s - loss: 0.8299 - acc: 0.7301 - val_loss: 0.4081 - val_acc: 0.9067

Epoch 00006: val_acc improved from 0.89667 to 0.90667, saving model to ./best_model_pseudo1.h5
Epoch 7/1000
 - 8s - loss: 0.7985 - acc: 0.7480 - val_loss: 0.3798 - val_acc: 0.9133

Epoch 00007: val_acc improved from 0.90667 to 0.91333, saving model to ./best_model_pseudo1.h5
Epoch 8/1000
 - 7s - loss: 0.7689 - acc: 0.7533 - val_loss: 0.3764 - val_acc: 0.9144

Epoch 00008: val_acc improved from 0.91333 to 0.91444, saving model to ./best_model_pseudo1.h5
Epoch 9/1000
 - 7s - loss: 0.7196 - acc: 0.7701 - val_loss: 0.3621 - val_acc: 0.9189

Epoch 00009: val_acc improved from 0.91444 to 0.91889, saving model to ./best_model_pseudo1.h5
Epoch 10/1000
 - 8s - loss: 0.7238 - acc: 0.7747 - val_loss: 0.3571 - val_acc: 0.9122

Epoch 00010: val_acc did not improve from 0.91889
Epoch 11/1000
Traceback (most recent call last):
  File "main.py", line 280, in <module>
    main()
  File "main.py", line 214, in main
    classweight, batch_param[i], n_nodes1[i], n_nodes2[i], n_nodes3[i], drop_out[i], model_path[i])
  File "main.py", line 75, in keras_learning
    class_weight = classweight, callbacks=[early_stopping, cb_checkpoint])
  File "/cluster/home/hochoi/.local/lib64/python3.6/site-packages/keras/engine/training.py", line 1039, in fit
    validation_steps=validation_steps)
  File "/cluster/home/hochoi/.local/lib64/python3.6/site-packages/keras/engine/training_arrays.py", line 212, in fit_loop
    verbose=0)
  File "/cluster/home/hochoi/.local/lib64/python3.6/site-packages/keras/engine/training_arrays.py", line 392, in test_loop
    batch_outs = f(ins_batch)
  File "/cluster/home/hochoi/.local/lib64/python3.6/site-packages/keras/backend/tensorflow_backend.py", line 2697, in __call__
    if hasattr(get_session(), '_make_callable_from_options'):
  File "/cluster/home/hochoi/.local/lib64/python3.6/site-packages/keras/backend/tensorflow_backend.py", line 189, in get_session
    with session.graph.as_default():
  File "/cluster/apps/python/3.6.0/x86_64/lib64/python3.6/contextlib.py", line 82, in __enter__
    return next(self.gen)
  File "/cluster/home/hochoi/.local/lib64/python3.6/site-packages/tensorflow/python/framework/ops.py", line 5251, in get_controller
    with super(_DefaultGraphStack, self).get_controller(
KeyboardInterrupt
