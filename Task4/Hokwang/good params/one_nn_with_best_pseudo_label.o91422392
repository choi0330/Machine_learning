Sender: LSF System <lsfadmin@eu-c7-108-07>
Subject: Job 91422392: <python3 single_nn_test.py> in cluster <euler> Done

Job <python3 single_nn_test.py> was submitted from host <eu-login-04-ng> by user <hochoi> in cluster <euler> at Sun May 19 00:36:00 2019
Job was executed on host(s) <2*eu-c7-108-07>, in queue <normal.4h>, as user <hochoi> in cluster <euler> at Sun May 19 00:36:22 2019
</cluster/home/hochoi> was used as the home directory.
</cluster/home/hochoi/Task4_main/Task4/Hokwang> was used as the working directory.
Started at Sun May 19 00:36:22 2019
Terminated at Sun May 19 00:54:31 2019
Results reported at Sun May 19 00:54:31 2019

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python3 single_nn_test.py
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   2124.67 sec.
    Max Memory :                                 698 MB
    Average Memory :                             654.71 MB
    Total Requested Memory :                     8192.00 MB
    Delta Memory :                               7494.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                18
    Run time :                                   1110 sec.
    Turnaround time :                            1111 sec.

The output (if any) follows:

Using TensorFlow backend.
/cluster/apps/python/3.6.0/x86_64/lib64/python3.6/site-packages/sklearn/preprocessing/data.py:160: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.
  warnings.warn("Numerical issues were encountered "
/cluster/apps/python/3.6.0/x86_64/lib64/python3.6/site-packages/sklearn/preprocessing/data.py:177: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. 
  warnings.warn("Numerical issues were encountered "
WARNING:tensorflow:From /cluster/home/hochoi/.local/lib64/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /cluster/home/hochoi/.local/lib64/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:tensorflow:From /cluster/home/hochoi/.local/lib64/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-05-19 00:36:29.993872: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-05-19 00:36:30.001789: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz
2019-05-19 00:36:30.002037: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x89fa110 executing computations on platform Host. Devices:
2019-05-19 00:36:30.002060: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
[INFO] Read hdf data
[INFO] Shuffled hdf data
[INFO] Split data: done!
[INFO] shape of x_train:(8100, 139)
[INFO] shape of x_test:(900, 139)
[INFO] shape of y_train:(8100,)
[INFO] shape of y_test:(900,)
[INFO] Read hdf data
[INFO] shape of test:(21000, 139)
[INFO] Read hdf data
[INFO] shape of test:(8000, 139)
number of features:  139
[INFO] shape of x_train:(27000, 139)
[INFO] shape of x_test:(3000, 139)
[INFO] shape of y_train:(27000,)
[INFO] shape of y_test:(3000,)
Train on 27000 samples, validate on 3000 samples
Epoch 1/1000
 - 7s - loss: 1.0842 - acc: 0.6946 - val_loss: 0.5720 - val_acc: 0.8687

Epoch 00001: val_acc improved from -inf to 0.86867, saving model to ./result/best_model1.h5
Epoch 2/1000
 - 6s - loss: 0.7050 - acc: 0.8036 - val_loss: 0.4020 - val_acc: 0.8997

Epoch 00002: val_acc improved from 0.86867 to 0.89967, saving model to ./result/best_model1.h5
Epoch 3/1000
 - 6s - loss: 0.5961 - acc: 0.8251 - val_loss: 0.3207 - val_acc: 0.9143

Epoch 00003: val_acc improved from 0.89967 to 0.91433, saving model to ./result/best_model1.h5
Epoch 4/1000
 - 7s - loss: 0.5174 - acc: 0.8474 - val_loss: 0.2724 - val_acc: 0.9240

Epoch 00004: val_acc improved from 0.91433 to 0.92400, saving model to ./result/best_model1.h5
Epoch 5/1000
 - 6s - loss: 0.4745 - acc: 0.8561 - val_loss: 0.2413 - val_acc: 0.9333

Epoch 00005: val_acc improved from 0.92400 to 0.93333, saving model to ./result/best_model1.h5
Epoch 6/1000
 - 7s - loss: 0.4466 - acc: 0.8650 - val_loss: 0.2187 - val_acc: 0.9387

Epoch 00006: val_acc improved from 0.93333 to 0.93867, saving model to ./result/best_model1.h5
Epoch 7/1000
 - 7s - loss: 0.4131 - acc: 0.8730 - val_loss: 0.2008 - val_acc: 0.9430

Epoch 00007: val_acc improved from 0.93867 to 0.94300, saving model to ./result/best_model1.h5
Epoch 8/1000
 - 6s - loss: 0.3883 - acc: 0.8795 - val_loss: 0.1867 - val_acc: 0.9463

Epoch 00008: val_acc improved from 0.94300 to 0.94633, saving model to ./result/best_model1.h5
Epoch 9/1000
 - 7s - loss: 0.3721 - acc: 0.8857 - val_loss: 0.1790 - val_acc: 0.9477

Epoch 00009: val_acc improved from 0.94633 to 0.94767, saving model to ./result/best_model1.h5
Epoch 10/1000
 - 7s - loss: 0.3554 - acc: 0.8883 - val_loss: 0.1678 - val_acc: 0.9490

Epoch 00010: val_acc improved from 0.94767 to 0.94900, saving model to ./result/best_model1.h5
Epoch 11/1000
 - 6s - loss: 0.3427 - acc: 0.8944 - val_loss: 0.1622 - val_acc: 0.9540

Epoch 00011: val_acc improved from 0.94900 to 0.95400, saving model to ./result/best_model1.h5
Epoch 12/1000
 - 6s - loss: 0.3306 - acc: 0.8962 - val_loss: 0.1560 - val_acc: 0.9527

Epoch 00012: val_acc did not improve from 0.95400
Epoch 13/1000
 - 7s - loss: 0.3129 - acc: 0.9031 - val_loss: 0.1537 - val_acc: 0.9550

Epoch 00013: val_acc improved from 0.95400 to 0.95500, saving model to ./result/best_model1.h5
Epoch 14/1000
 - 6s - loss: 0.3066 - acc: 0.9036 - val_loss: 0.1474 - val_acc: 0.9560

Epoch 00014: val_acc improved from 0.95500 to 0.95600, saving model to ./result/best_model1.h5
Epoch 15/1000
 - 7s - loss: 0.3002 - acc: 0.9080 - val_loss: 0.1430 - val_acc: 0.9540

Epoch 00015: val_acc did not improve from 0.95600
Epoch 16/1000
 - 7s - loss: 0.2833 - acc: 0.9107 - val_loss: 0.1396 - val_acc: 0.9583

Epoch 00016: val_acc improved from 0.95600 to 0.95833, saving model to ./result/best_model1.h5
Epoch 17/1000
 - 6s - loss: 0.2761 - acc: 0.9137 - val_loss: 0.1380 - val_acc: 0.9580

Epoch 00017: val_acc did not improve from 0.95833
Epoch 18/1000
 - 7s - loss: 0.2723 - acc: 0.9165 - val_loss: 0.1339 - val_acc: 0.9617

Epoch 00018: val_acc improved from 0.95833 to 0.96167, saving model to ./result/best_model1.h5
Epoch 19/1000
 - 7s - loss: 0.2641 - acc: 0.9163 - val_loss: 0.1304 - val_acc: 0.9620

Epoch 00019: val_acc improved from 0.96167 to 0.96200, saving model to ./result/best_model1.h5
Epoch 20/1000
 - 7s - loss: 0.2581 - acc: 0.9204 - val_loss: 0.1296 - val_acc: 0.9593

Epoch 00020: val_acc did not improve from 0.96200
Epoch 21/1000
 - 7s - loss: 0.2508 - acc: 0.9220 - val_loss: 0.1274 - val_acc: 0.9620

Epoch 00021: val_acc did not improve from 0.96200
Epoch 22/1000
 - 7s - loss: 0.2498 - acc: 0.9237 - val_loss: 0.1239 - val_acc: 0.9620

Epoch 00022: val_acc did not improve from 0.96200
Epoch 23/1000
 - 6s - loss: 0.2403 - acc: 0.9242 - val_loss: 0.1247 - val_acc: 0.9623

Epoch 00023: val_acc improved from 0.96200 to 0.96233, saving model to ./result/best_model1.h5
Epoch 24/1000
 - 7s - loss: 0.2294 - acc: 0.9283 - val_loss: 0.1213 - val_acc: 0.9640

Epoch 00024: val_acc improved from 0.96233 to 0.96400, saving model to ./result/best_model1.h5
Epoch 25/1000
 - 7s - loss: 0.2254 - acc: 0.9318 - val_loss: 0.1228 - val_acc: 0.9627

Epoch 00025: val_acc did not improve from 0.96400
Epoch 26/1000
 - 6s - loss: 0.2242 - acc: 0.9297 - val_loss: 0.1185 - val_acc: 0.9623

Epoch 00026: val_acc did not improve from 0.96400
Epoch 27/1000
 - 7s - loss: 0.2177 - acc: 0.9316 - val_loss: 0.1184 - val_acc: 0.9620

Epoch 00027: val_acc did not improve from 0.96400
Epoch 28/1000
 - 7s - loss: 0.2190 - acc: 0.9326 - val_loss: 0.1190 - val_acc: 0.9610

Epoch 00028: val_acc did not improve from 0.96400
Epoch 29/1000
 - 7s - loss: 0.2112 - acc: 0.9350 - val_loss: 0.1177 - val_acc: 0.9627

Epoch 00029: val_acc did not improve from 0.96400
Epoch 30/1000
 - 7s - loss: 0.2050 - acc: 0.9355 - val_loss: 0.1163 - val_acc: 0.9613

Epoch 00030: val_acc did not improve from 0.96400
Epoch 31/1000
 - 7s - loss: 0.2021 - acc: 0.9369 - val_loss: 0.1147 - val_acc: 0.9643

Epoch 00031: val_acc improved from 0.96400 to 0.96433, saving model to ./result/best_model1.h5
Epoch 32/1000
 - 6s - loss: 0.2002 - acc: 0.9375 - val_loss: 0.1128 - val_acc: 0.9637

Epoch 00032: val_acc did not improve from 0.96433
Epoch 33/1000
 - 6s - loss: 0.1961 - acc: 0.9384 - val_loss: 0.1114 - val_acc: 0.9630

Epoch 00033: val_acc did not improve from 0.96433
Epoch 34/1000
 - 7s - loss: 0.1898 - acc: 0.9398 - val_loss: 0.1113 - val_acc: 0.9633

Epoch 00034: val_acc did not improve from 0.96433
Epoch 35/1000
 - 6s - loss: 0.1915 - acc: 0.9393 - val_loss: 0.1048 - val_acc: 0.9667

Epoch 00035: val_acc improved from 0.96433 to 0.96667, saving model to ./result/best_model1.h5
Epoch 36/1000
 - 6s - loss: 0.1854 - acc: 0.9417 - val_loss: 0.1070 - val_acc: 0.9630

Epoch 00036: val_acc did not improve from 0.96667
Epoch 37/1000
 - 7s - loss: 0.1825 - acc: 0.9431 - val_loss: 0.1068 - val_acc: 0.9633

Epoch 00037: val_acc did not improve from 0.96667
Epoch 38/1000
 - 6s - loss: 0.1826 - acc: 0.9437 - val_loss: 0.1071 - val_acc: 0.9623

Epoch 00038: val_acc did not improve from 0.96667
Epoch 39/1000
 - 6s - loss: 0.1787 - acc: 0.9437 - val_loss: 0.1058 - val_acc: 0.9653

Epoch 00039: val_acc did not improve from 0.96667
Epoch 40/1000
 - 7s - loss: 0.1739 - acc: 0.9464 - val_loss: 0.1050 - val_acc: 0.9670

Epoch 00040: val_acc improved from 0.96667 to 0.96700, saving model to ./result/best_model1.h5
Epoch 41/1000
 - 7s - loss: 0.1780 - acc: 0.9441 - val_loss: 0.1062 - val_acc: 0.9643

Epoch 00041: val_acc did not improve from 0.96700
Epoch 42/1000
 - 6s - loss: 0.1716 - acc: 0.9444 - val_loss: 0.1027 - val_acc: 0.9663

Epoch 00042: val_acc did not improve from 0.96700
Epoch 43/1000
 - 7s - loss: 0.1661 - acc: 0.9481 - val_loss: 0.1043 - val_acc: 0.9633

Epoch 00043: val_acc did not improve from 0.96700
Epoch 44/1000
 - 6s - loss: 0.1669 - acc: 0.9471 - val_loss: 0.1022 - val_acc: 0.9633

Epoch 00044: val_acc did not improve from 0.96700
Epoch 45/1000
 - 6s - loss: 0.1672 - acc: 0.9472 - val_loss: 0.1021 - val_acc: 0.9663

Epoch 00045: val_acc did not improve from 0.96700
Epoch 46/1000
 - 7s - loss: 0.1659 - acc: 0.9487 - val_loss: 0.0994 - val_acc: 0.9680

Epoch 00046: val_acc improved from 0.96700 to 0.96800, saving model to ./result/best_model1.h5
Epoch 47/1000
 - 6s - loss: 0.1629 - acc: 0.9473 - val_loss: 0.0984 - val_acc: 0.9697

Epoch 00047: val_acc improved from 0.96800 to 0.96967, saving model to ./result/best_model1.h5
Epoch 48/1000
 - 6s - loss: 0.1545 - acc: 0.9528 - val_loss: 0.1019 - val_acc: 0.9660

Epoch 00048: val_acc did not improve from 0.96967
Epoch 49/1000
 - 7s - loss: 0.1546 - acc: 0.9519 - val_loss: 0.0991 - val_acc: 0.9687

Epoch 00049: val_acc did not improve from 0.96967
Epoch 50/1000
 - 6s - loss: 0.1569 - acc: 0.9521 - val_loss: 0.0964 - val_acc: 0.9690

Epoch 00050: val_acc did not improve from 0.96967
Epoch 51/1000
 - 7s - loss: 0.1509 - acc: 0.9530 - val_loss: 0.1003 - val_acc: 0.9637

Epoch 00051: val_acc did not improve from 0.96967
Epoch 52/1000
 - 7s - loss: 0.1487 - acc: 0.9533 - val_loss: 0.0984 - val_acc: 0.9683

Epoch 00052: val_acc did not improve from 0.96967
Epoch 53/1000
 - 7s - loss: 0.1521 - acc: 0.9534 - val_loss: 0.0986 - val_acc: 0.9683

Epoch 00053: val_acc did not improve from 0.96967
Epoch 54/1000
 - 6s - loss: 0.1465 - acc: 0.9538 - val_loss: 0.1005 - val_acc: 0.9633

Epoch 00054: val_acc did not improve from 0.96967
Epoch 55/1000
 - 7s - loss: 0.1501 - acc: 0.9535 - val_loss: 0.1007 - val_acc: 0.9697

Epoch 00055: val_acc improved from 0.96967 to 0.96967, saving model to ./result/best_model1.h5
Epoch 56/1000
 - 6s - loss: 0.1452 - acc: 0.9544 - val_loss: 0.0994 - val_acc: 0.9673

Epoch 00056: val_acc did not improve from 0.96967
Epoch 57/1000
 - 7s - loss: 0.1424 - acc: 0.9557 - val_loss: 0.0996 - val_acc: 0.9667

Epoch 00057: val_acc did not improve from 0.96967
Epoch 58/1000
 - 7s - loss: 0.1420 - acc: 0.9550 - val_loss: 0.0967 - val_acc: 0.9693

Epoch 00058: val_acc did not improve from 0.96967
Epoch 59/1000
 - 7s - loss: 0.1406 - acc: 0.9556 - val_loss: 0.0973 - val_acc: 0.9693

Epoch 00059: val_acc did not improve from 0.96967
Epoch 60/1000
 - 6s - loss: 0.1399 - acc: 0.9541 - val_loss: 0.0975 - val_acc: 0.9670

Epoch 00060: val_acc did not improve from 0.96967
Epoch 61/1000
 - 7s - loss: 0.1407 - acc: 0.9551 - val_loss: 0.0964 - val_acc: 0.9657

Epoch 00061: val_acc did not improve from 0.96967
Epoch 62/1000
 - 7s - loss: 0.1358 - acc: 0.9567 - val_loss: 0.0961 - val_acc: 0.9700

Epoch 00062: val_acc improved from 0.96967 to 0.97000, saving model to ./result/best_model1.h5
Epoch 63/1000
 - 6s - loss: 0.1314 - acc: 0.9577 - val_loss: 0.0994 - val_acc: 0.9657

Epoch 00063: val_acc did not improve from 0.97000
Epoch 64/1000
 - 6s - loss: 0.1383 - acc: 0.9561 - val_loss: 0.0965 - val_acc: 0.9687

Epoch 00064: val_acc did not improve from 0.97000
Epoch 65/1000
 - 7s - loss: 0.1322 - acc: 0.9587 - val_loss: 0.0948 - val_acc: 0.9677

Epoch 00065: val_acc did not improve from 0.97000
Epoch 66/1000
 - 7s - loss: 0.1316 - acc: 0.9583 - val_loss: 0.0955 - val_acc: 0.9670

Epoch 00066: val_acc did not improve from 0.97000
Epoch 67/1000
 - 7s - loss: 0.1305 - acc: 0.9570 - val_loss: 0.0918 - val_acc: 0.9703

Epoch 00067: val_acc improved from 0.97000 to 0.97033, saving model to ./result/best_model1.h5
Epoch 68/1000
 - 7s - loss: 0.1300 - acc: 0.9586 - val_loss: 0.0935 - val_acc: 0.9687

Epoch 00068: val_acc did not improve from 0.97033
Epoch 69/1000
 - 6s - loss: 0.1270 - acc: 0.9596 - val_loss: 0.0918 - val_acc: 0.9707

Epoch 00069: val_acc improved from 0.97033 to 0.97067, saving model to ./result/best_model1.h5
Epoch 70/1000
 - 7s - loss: 0.1287 - acc: 0.9596 - val_loss: 0.0949 - val_acc: 0.9680

Epoch 00070: val_acc did not improve from 0.97067
Epoch 71/1000
 - 7s - loss: 0.1294 - acc: 0.9584 - val_loss: 0.0923 - val_acc: 0.9690

Epoch 00071: val_acc did not improve from 0.97067
Epoch 72/1000
 - 6s - loss: 0.1227 - acc: 0.9617 - val_loss: 0.0967 - val_acc: 0.9667

Epoch 00072: val_acc did not improve from 0.97067
Epoch 73/1000
 - 6s - loss: 0.1255 - acc: 0.9595 - val_loss: 0.0945 - val_acc: 0.9693

Epoch 00073: val_acc did not improve from 0.97067
Epoch 74/1000
 - 7s - loss: 0.1243 - acc: 0.9604 - val_loss: 0.0920 - val_acc: 0.9690

Epoch 00074: val_acc did not improve from 0.97067
Epoch 75/1000
 - 6s - loss: 0.1265 - acc: 0.9594 - val_loss: 0.0973 - val_acc: 0.9660

Epoch 00075: val_acc did not improve from 0.97067
Epoch 76/1000
 - 7s - loss: 0.1226 - acc: 0.9628 - val_loss: 0.0953 - val_acc: 0.9690

Epoch 00076: val_acc did not improve from 0.97067
Epoch 77/1000
 - 7s - loss: 0.1210 - acc: 0.9622 - val_loss: 0.0934 - val_acc: 0.9690

Epoch 00077: val_acc did not improve from 0.97067
Epoch 78/1000
 - 6s - loss: 0.1184 - acc: 0.9631 - val_loss: 0.0931 - val_acc: 0.9690

Epoch 00078: val_acc did not improve from 0.97067
Epoch 79/1000
 - 7s - loss: 0.1201 - acc: 0.9628 - val_loss: 0.0912 - val_acc: 0.9700

Epoch 00079: val_acc did not improve from 0.97067
Epoch 80/1000
 - 7s - loss: 0.1209 - acc: 0.9603 - val_loss: 0.0938 - val_acc: 0.9683

Epoch 00080: val_acc did not improve from 0.97067
Epoch 81/1000
 - 6s - loss: 0.1183 - acc: 0.9631 - val_loss: 0.0921 - val_acc: 0.9717

Epoch 00081: val_acc improved from 0.97067 to 0.97167, saving model to ./result/best_model1.h5
Epoch 82/1000
 - 7s - loss: 0.1144 - acc: 0.9638 - val_loss: 0.0904 - val_acc: 0.9703

Epoch 00082: val_acc did not improve from 0.97167
Epoch 83/1000
 - 7s - loss: 0.1179 - acc: 0.9636 - val_loss: 0.0915 - val_acc: 0.9680

Epoch 00083: val_acc did not improve from 0.97167
Epoch 84/1000
 - 7s - loss: 0.1126 - acc: 0.9645 - val_loss: 0.0930 - val_acc: 0.9697

Epoch 00084: val_acc did not improve from 0.97167
Epoch 85/1000
 - 7s - loss: 0.1109 - acc: 0.9660 - val_loss: 0.0915 - val_acc: 0.9697

Epoch 00085: val_acc did not improve from 0.97167
Epoch 86/1000
 - 7s - loss: 0.1136 - acc: 0.9633 - val_loss: 0.0899 - val_acc: 0.9700

Epoch 00086: val_acc did not improve from 0.97167
Epoch 87/1000
 - 6s - loss: 0.1146 - acc: 0.9630 - val_loss: 0.0914 - val_acc: 0.9677

Epoch 00087: val_acc did not improve from 0.97167
Epoch 88/1000
 - 7s - loss: 0.1110 - acc: 0.9651 - val_loss: 0.0902 - val_acc: 0.9680

Epoch 00088: val_acc did not improve from 0.97167
Epoch 89/1000
 - 7s - loss: 0.1103 - acc: 0.9647 - val_loss: 0.0893 - val_acc: 0.9670

Epoch 00089: val_acc did not improve from 0.97167
Epoch 90/1000
 - 6s - loss: 0.1121 - acc: 0.9658 - val_loss: 0.0896 - val_acc: 0.9680

Epoch 00090: val_acc did not improve from 0.97167
Epoch 91/1000
 - 7s - loss: 0.1043 - acc: 0.9678 - val_loss: 0.0901 - val_acc: 0.9683

Epoch 00091: val_acc did not improve from 0.97167
Epoch 92/1000
 - 7s - loss: 0.1057 - acc: 0.9664 - val_loss: 0.0910 - val_acc: 0.9697

Epoch 00092: val_acc did not improve from 0.97167
Epoch 93/1000
 - 7s - loss: 0.1059 - acc: 0.9655 - val_loss: 0.0928 - val_acc: 0.9713

Epoch 00093: val_acc did not improve from 0.97167
Epoch 94/1000
 - 7s - loss: 0.1075 - acc: 0.9657 - val_loss: 0.0919 - val_acc: 0.9680

Epoch 00094: val_acc did not improve from 0.97167
Epoch 95/1000
 - 7s - loss: 0.1021 - acc: 0.9687 - val_loss: 0.0924 - val_acc: 0.9700

Epoch 00095: val_acc did not improve from 0.97167
Epoch 96/1000
 - 7s - loss: 0.1085 - acc: 0.9653 - val_loss: 0.0917 - val_acc: 0.9717

Epoch 00096: val_acc did not improve from 0.97167
Epoch 97/1000
 - 7s - loss: 0.1045 - acc: 0.9672 - val_loss: 0.0910 - val_acc: 0.9693

Epoch 00097: val_acc did not improve from 0.97167
Epoch 98/1000
 - 7s - loss: 0.1025 - acc: 0.9670 - val_loss: 0.0891 - val_acc: 0.9707

Epoch 00098: val_acc did not improve from 0.97167
Epoch 99/1000
 - 7s - loss: 0.1064 - acc: 0.9656 - val_loss: 0.0910 - val_acc: 0.9700

Epoch 00099: val_acc did not improve from 0.97167
Epoch 100/1000
 - 7s - loss: 0.1026 - acc: 0.9670 - val_loss: 0.0914 - val_acc: 0.9677

Epoch 00100: val_acc did not improve from 0.97167
Epoch 101/1000
 - 7s - loss: 0.1010 - acc: 0.9674 - val_loss: 0.0935 - val_acc: 0.9670

Epoch 00101: val_acc did not improve from 0.97167
Epoch 102/1000
 - 7s - loss: 0.1008 - acc: 0.9674 - val_loss: 0.0920 - val_acc: 0.9710

Epoch 00102: val_acc did not improve from 0.97167
Epoch 103/1000
 - 7s - loss: 0.0984 - acc: 0.9681 - val_loss: 0.0913 - val_acc: 0.9687

Epoch 00103: val_acc did not improve from 0.97167
Epoch 104/1000
 - 7s - loss: 0.0975 - acc: 0.9696 - val_loss: 0.0880 - val_acc: 0.9710

Epoch 00104: val_acc did not improve from 0.97167
Epoch 105/1000
 - 6s - loss: 0.0983 - acc: 0.9690 - val_loss: 0.0877 - val_acc: 0.9707

Epoch 00105: val_acc did not improve from 0.97167
Epoch 106/1000
 - 7s - loss: 0.0996 - acc: 0.9683 - val_loss: 0.0874 - val_acc: 0.9717

Epoch 00106: val_acc did not improve from 0.97167
Epoch 107/1000
 - 6s - loss: 0.0961 - acc: 0.9693 - val_loss: 0.0928 - val_acc: 0.9687

Epoch 00107: val_acc did not improve from 0.97167
Epoch 108/1000
 - 6s - loss: 0.0956 - acc: 0.9688 - val_loss: 0.0894 - val_acc: 0.9683

Epoch 00108: val_acc did not improve from 0.97167
Epoch 109/1000
 - 6s - loss: 0.0988 - acc: 0.9684 - val_loss: 0.0889 - val_acc: 0.9703

Epoch 00109: val_acc did not improve from 0.97167
Epoch 110/1000
 - 6s - loss: 0.1005 - acc: 0.9674 - val_loss: 0.0890 - val_acc: 0.9703

Epoch 00110: val_acc did not improve from 0.97167
Epoch 111/1000
 - 7s - loss: 0.0993 - acc: 0.9684 - val_loss: 0.0877 - val_acc: 0.9717

Epoch 00111: val_acc did not improve from 0.97167
Epoch 112/1000
 - 7s - loss: 0.0948 - acc: 0.9713 - val_loss: 0.0878 - val_acc: 0.9687

Epoch 00112: val_acc did not improve from 0.97167
Epoch 113/1000
 - 7s - loss: 0.0928 - acc: 0.9705 - val_loss: 0.0864 - val_acc: 0.9693

Epoch 00113: val_acc did not improve from 0.97167
Epoch 114/1000
 - 7s - loss: 0.0953 - acc: 0.9697 - val_loss: 0.0912 - val_acc: 0.9690

Epoch 00114: val_acc did not improve from 0.97167
Epoch 115/1000
 - 7s - loss: 0.0954 - acc: 0.9691 - val_loss: 0.0920 - val_acc: 0.9677

Epoch 00115: val_acc did not improve from 0.97167
Epoch 116/1000
 - 7s - loss: 0.0875 - acc: 0.9727 - val_loss: 0.0877 - val_acc: 0.9690

Epoch 00116: val_acc did not improve from 0.97167
Epoch 117/1000
 - 7s - loss: 0.0903 - acc: 0.9717 - val_loss: 0.0898 - val_acc: 0.9687

Epoch 00117: val_acc did not improve from 0.97167
Epoch 118/1000
 - 6s - loss: 0.0906 - acc: 0.9704 - val_loss: 0.0891 - val_acc: 0.9690

Epoch 00118: val_acc did not improve from 0.97167
Epoch 119/1000
 - 7s - loss: 0.0854 - acc: 0.9736 - val_loss: 0.0882 - val_acc: 0.9713

Epoch 00119: val_acc did not improve from 0.97167
Epoch 120/1000
 - 7s - loss: 0.0916 - acc: 0.9704 - val_loss: 0.0903 - val_acc: 0.9703

Epoch 00120: val_acc did not improve from 0.97167
Epoch 121/1000
 - 7s - loss: 0.0896 - acc: 0.9714 - val_loss: 0.0938 - val_acc: 0.9663

Epoch 00121: val_acc did not improve from 0.97167
Epoch 122/1000
 - 7s - loss: 0.0918 - acc: 0.9707 - val_loss: 0.0915 - val_acc: 0.9697

Epoch 00122: val_acc did not improve from 0.97167
Epoch 123/1000
 - 6s - loss: 0.0843 - acc: 0.9741 - val_loss: 0.0896 - val_acc: 0.9683

Epoch 00123: val_acc did not improve from 0.97167
Epoch 124/1000
 - 6s - loss: 0.0862 - acc: 0.9719 - val_loss: 0.0911 - val_acc: 0.9707

Epoch 00124: val_acc did not improve from 0.97167
Epoch 125/1000
 - 7s - loss: 0.0905 - acc: 0.9717 - val_loss: 0.0915 - val_acc: 0.9657

Epoch 00125: val_acc did not improve from 0.97167
Epoch 126/1000
 - 6s - loss: 0.0835 - acc: 0.9738 - val_loss: 0.0898 - val_acc: 0.9690

Epoch 00126: val_acc did not improve from 0.97167
Epoch 127/1000
 - 6s - loss: 0.0830 - acc: 0.9735 - val_loss: 0.0914 - val_acc: 0.9693

Epoch 00127: val_acc did not improve from 0.97167
Epoch 128/1000
 - 7s - loss: 0.0905 - acc: 0.9705 - val_loss: 0.0935 - val_acc: 0.9680

Epoch 00128: val_acc did not improve from 0.97167
Epoch 129/1000
 - 7s - loss: 0.0838 - acc: 0.9730 - val_loss: 0.0882 - val_acc: 0.9687

Epoch 00129: val_acc did not improve from 0.97167
Epoch 130/1000
 - 6s - loss: 0.0867 - acc: 0.9724 - val_loss: 0.0895 - val_acc: 0.9687

Epoch 00130: val_acc did not improve from 0.97167
Epoch 131/1000
 - 6s - loss: 0.0876 - acc: 0.9716 - val_loss: 0.0889 - val_acc: 0.9697

Epoch 00131: val_acc did not improve from 0.97167
Epoch 132/1000
 - 6s - loss: 0.0854 - acc: 0.9735 - val_loss: 0.0889 - val_acc: 0.9700

Epoch 00132: val_acc did not improve from 0.97167
Epoch 133/1000
 - 6s - loss: 0.0822 - acc: 0.9740 - val_loss: 0.0892 - val_acc: 0.9703

Epoch 00133: val_acc did not improve from 0.97167
Epoch 134/1000
 - 6s - loss: 0.0832 - acc: 0.9731 - val_loss: 0.0917 - val_acc: 0.9683

Epoch 00134: val_acc did not improve from 0.97167
Epoch 135/1000
 - 7s - loss: 0.0853 - acc: 0.9729 - val_loss: 0.0887 - val_acc: 0.9707

Epoch 00135: val_acc did not improve from 0.97167
Epoch 136/1000
 - 6s - loss: 0.0823 - acc: 0.9734 - val_loss: 0.0884 - val_acc: 0.9727

Epoch 00136: val_acc improved from 0.97167 to 0.97267, saving model to ./result/best_model1.h5
Epoch 137/1000
 - 6s - loss: 0.0847 - acc: 0.9737 - val_loss: 0.0886 - val_acc: 0.9710

Epoch 00137: val_acc did not improve from 0.97267
Epoch 138/1000
 - 6s - loss: 0.0817 - acc: 0.9750 - val_loss: 0.0927 - val_acc: 0.9673

Epoch 00138: val_acc did not improve from 0.97267
Epoch 139/1000
 - 7s - loss: 0.0777 - acc: 0.9754 - val_loss: 0.0888 - val_acc: 0.9703

Epoch 00139: val_acc did not improve from 0.97267
Epoch 140/1000
 - 6s - loss: 0.0807 - acc: 0.9745 - val_loss: 0.0912 - val_acc: 0.9683

Epoch 00140: val_acc did not improve from 0.97267
Epoch 141/1000
 - 7s - loss: 0.0809 - acc: 0.9744 - val_loss: 0.0911 - val_acc: 0.9677

Epoch 00141: val_acc did not improve from 0.97267
Epoch 142/1000
 - 6s - loss: 0.0802 - acc: 0.9739 - val_loss: 0.0882 - val_acc: 0.9703

Epoch 00142: val_acc did not improve from 0.97267
Epoch 143/1000
 - 6s - loss: 0.0783 - acc: 0.9755 - val_loss: 0.0909 - val_acc: 0.9680

Epoch 00143: val_acc did not improve from 0.97267
Epoch 144/1000
 - 6s - loss: 0.0751 - acc: 0.9753 - val_loss: 0.0914 - val_acc: 0.9663

Epoch 00144: val_acc did not improve from 0.97267
Epoch 145/1000
 - 6s - loss: 0.0779 - acc: 0.9743 - val_loss: 0.0886 - val_acc: 0.9690

Epoch 00145: val_acc did not improve from 0.97267
Epoch 146/1000
 - 7s - loss: 0.0767 - acc: 0.9750 - val_loss: 0.0911 - val_acc: 0.9690

Epoch 00146: val_acc did not improve from 0.97267
Epoch 147/1000
 - 7s - loss: 0.0762 - acc: 0.9750 - val_loss: 0.0879 - val_acc: 0.9697

Epoch 00147: val_acc did not improve from 0.97267
Epoch 148/1000
 - 6s - loss: 0.0732 - acc: 0.9768 - val_loss: 0.0868 - val_acc: 0.9693

Epoch 00148: val_acc did not improve from 0.97267
Epoch 149/1000
 - 7s - loss: 0.0759 - acc: 0.9757 - val_loss: 0.0886 - val_acc: 0.9703

Epoch 00149: val_acc did not improve from 0.97267
Epoch 150/1000
 - 7s - loss: 0.0753 - acc: 0.9761 - val_loss: 0.0929 - val_acc: 0.9683

Epoch 00150: val_acc did not improve from 0.97267
Epoch 151/1000
 - 7s - loss: 0.0747 - acc: 0.9764 - val_loss: 0.0907 - val_acc: 0.9690

Epoch 00151: val_acc did not improve from 0.97267
Epoch 152/1000
 - 6s - loss: 0.0740 - acc: 0.9760 - val_loss: 0.0896 - val_acc: 0.9700

Epoch 00152: val_acc did not improve from 0.97267
Epoch 153/1000
 - 7s - loss: 0.0762 - acc: 0.9763 - val_loss: 0.0936 - val_acc: 0.9673

Epoch 00153: val_acc did not improve from 0.97267
Epoch 154/1000
 - 7s - loss: 0.0726 - acc: 0.9766 - val_loss: 0.0914 - val_acc: 0.9697

Epoch 00154: val_acc did not improve from 0.97267
Epoch 155/1000
 - 7s - loss: 0.0733 - acc: 0.9769 - val_loss: 0.0914 - val_acc: 0.9690

Epoch 00155: val_acc did not improve from 0.97267
Epoch 156/1000
 - 7s - loss: 0.0713 - acc: 0.9778 - val_loss: 0.0890 - val_acc: 0.9690

Epoch 00156: val_acc did not improve from 0.97267
Epoch 157/1000
 - 7s - loss: 0.0746 - acc: 0.9753 - val_loss: 0.0924 - val_acc: 0.9683

Epoch 00157: val_acc did not improve from 0.97267
Epoch 158/1000
 - 6s - loss: 0.0720 - acc: 0.9769 - val_loss: 0.0885 - val_acc: 0.9697

Epoch 00158: val_acc did not improve from 0.97267
Epoch 159/1000
 - 7s - loss: 0.0695 - acc: 0.9787 - val_loss: 0.0882 - val_acc: 0.9703

Epoch 00159: val_acc did not improve from 0.97267
Epoch 160/1000
 - 7s - loss: 0.0697 - acc: 0.9775 - val_loss: 0.0918 - val_acc: 0.9653

Epoch 00160: val_acc did not improve from 0.97267
Epoch 161/1000
 - 6s - loss: 0.0720 - acc: 0.9770 - val_loss: 0.0867 - val_acc: 0.9733

Epoch 00161: val_acc improved from 0.97267 to 0.97333, saving model to ./result/best_model1.h5
Epoch 162/1000
 - 7s - loss: 0.0695 - acc: 0.9777 - val_loss: 0.0903 - val_acc: 0.9690

Epoch 00162: val_acc did not improve from 0.97333
Epoch 163/1000
 - 6s - loss: 0.0705 - acc: 0.9769 - val_loss: 0.0889 - val_acc: 0.9697

Epoch 00163: val_acc did not improve from 0.97333
Epoch 00163: early stopping

   32/27000 [..............................] - ETA: 2:15
  672/27000 [..............................] - ETA: 8s  
 1440/27000 [>.............................] - ETA: 4s
 2240/27000 [=>............................] - ETA: 3s
 3040/27000 [==>...........................] - ETA: 2s
 3840/27000 [===>..........................] - ETA: 2s
 4640/27000 [====>.........................] - ETA: 2s
 5440/27000 [=====>........................] - ETA: 2s
 6240/27000 [=====>........................] - ETA: 1s
 7040/27000 [======>.......................] - ETA: 1s
 7840/27000 [=======>......................] - ETA: 1s
 8640/27000 [========>.....................] - ETA: 1s
 9440/27000 [=========>....................] - ETA: 1s
10208/27000 [==========>...................] - ETA: 1s
10976/27000 [===========>..................] - ETA: 1s
11744/27000 [============>.................] - ETA: 1s
12512/27000 [============>.................] - ETA: 1s
13280/27000 [=============>................] - ETA: 1s
14016/27000 [==============>...............] - ETA: 1s
14784/27000 [===============>..............] - ETA: 0s
15552/27000 [================>.............] - ETA: 0s
16192/27000 [================>.............] - ETA: 0s
16928/27000 [=================>............] - ETA: 0s
17664/27000 [==================>...........] - ETA: 0s
18432/27000 [===================>..........] - ETA: 0s
19168/27000 [====================>.........] - ETA: 0s
19936/27000 [=====================>........] - ETA: 0s
20704/27000 [======================>.......] - ETA: 0s
21440/27000 [======================>.......] - ETA: 0s
22208/27000 [=======================>......] - ETA: 0s
22976/27000 [========================>.....] - ETA: 0s
23680/27000 [=========================>....] - ETA: 0s
24416/27000 [==========================>...] - ETA: 0s
25184/27000 [==========================>...] - ETA: 0s
25920/27000 [===========================>..] - ETA: 0s
26688/27000 [============================>.] - ETA: 0s
27000/27000 [==============================] - 2s 73us/step

  32/3000 [..............................] - ETA: 0s
 800/3000 [=======>......................] - ETA: 0s
1568/3000 [==============>...............] - ETA: 0s
2304/3000 [======================>.......] - ETA: 0s
3000/3000 [==============================] - 0s 68us/step
[INFO] Train Score: 0.005765078078748451
[INFO] Train accuracy: 0.9997037037037036
[INFO] Test Score: 0.08669675837953886
[INFO] Test accuracy: 0.9733333331743876
batch param:  32
n_nodes1:  500
n_nodes2:  500
n_nodes3:  300
drop_out:  0.28
